{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5889 images belonging to 5 classes.\n",
      "Found 1471 images belonging to 5 classes.\n",
      "Starting training...\n",
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2168s\u001b[0m 12s/step - accuracy: 0.2795 - loss: 1.5979 - val_accuracy: 0.5486 - val_loss: 1.2787 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2470s\u001b[0m 13s/step - accuracy: 0.6055 - loss: 1.2007 - val_accuracy: 0.6159 - val_loss: 1.1147 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2303s\u001b[0m 12s/step - accuracy: 0.6531 - loss: 1.0748 - val_accuracy: 0.6533 - val_loss: 1.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2240s\u001b[0m 12s/step - accuracy: 0.6753 - loss: 0.9908 - val_accuracy: 0.6492 - val_loss: 0.9564 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2142s\u001b[0m 12s/step - accuracy: 0.6945 - loss: 0.9204 - val_accuracy: 0.6859 - val_loss: 0.8980 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2143s\u001b[0m 12s/step - accuracy: 0.7067 - loss: 0.8735 - val_accuracy: 0.6934 - val_loss: 0.8709 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2177s\u001b[0m 12s/step - accuracy: 0.7285 - loss: 0.8243 - val_accuracy: 0.7220 - val_loss: 0.8296 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2202s\u001b[0m 12s/step - accuracy: 0.7293 - loss: 0.8221 - val_accuracy: 0.7186 - val_loss: 0.8108 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2081s\u001b[0m 11s/step - accuracy: 0.7469 - loss: 0.7725 - val_accuracy: 0.7192 - val_loss: 0.7958 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2365s\u001b[0m 13s/step - accuracy: 0.7379 - loss: 0.7721 - val_accuracy: 0.7369 - val_loss: 0.7752 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1985s\u001b[0m 11s/step - accuracy: 0.7582 - loss: 0.7504 - val_accuracy: 0.7267 - val_loss: 0.7744 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 10s/step - accuracy: 0.7693 - loss: 0.7252 - val_accuracy: 0.7383 - val_loss: 0.7600 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2222s\u001b[0m 12s/step - accuracy: 0.7730 - loss: 0.7029 - val_accuracy: 0.7478 - val_loss: 0.7521 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2019s\u001b[0m 11s/step - accuracy: 0.7769 - loss: 0.6804 - val_accuracy: 0.7478 - val_loss: 0.7321 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2096s\u001b[0m 11s/step - accuracy: 0.7726 - loss: 0.6878 - val_accuracy: 0.7512 - val_loss: 0.7217 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2068s\u001b[0m 11s/step - accuracy: 0.7805 - loss: 0.6737 - val_accuracy: 0.7485 - val_loss: 0.7107 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2113s\u001b[0m 11s/step - accuracy: 0.7828 - loss: 0.6640 - val_accuracy: 0.7471 - val_loss: 0.7089 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2363s\u001b[0m 13s/step - accuracy: 0.7772 - loss: 0.6649 - val_accuracy: 0.7430 - val_loss: 0.6997 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2204s\u001b[0m 12s/step - accuracy: 0.7872 - loss: 0.6394 - val_accuracy: 0.7512 - val_loss: 0.6981 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2337s\u001b[0m 13s/step - accuracy: 0.7901 - loss: 0.6354 - val_accuracy: 0.7525 - val_loss: 0.6980 - learning_rate: 1.0000e-04\n",
      "Fine-tuning the model...\n",
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12419s\u001b[0m 67s/step - accuracy: 0.5435 - loss: 1.1779 - val_accuracy: 0.6975 - val_loss: 0.8023 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12200s\u001b[0m 66s/step - accuracy: 0.7442 - loss: 0.7670 - val_accuracy: 0.7308 - val_loss: 0.7381 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12696s\u001b[0m 69s/step - accuracy: 0.7817 - loss: 0.6534 - val_accuracy: 0.7675 - val_loss: 0.6663 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13553s\u001b[0m 73s/step - accuracy: 0.7992 - loss: 0.6064 - val_accuracy: 0.7736 - val_loss: 0.6496 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12500s\u001b[0m 67s/step - accuracy: 0.8167 - loss: 0.5370 - val_accuracy: 0.7804 - val_loss: 0.6158 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13063s\u001b[0m 71s/step - accuracy: 0.8364 - loss: 0.4805 - val_accuracy: 0.7709 - val_loss: 0.5906 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11848s\u001b[0m 64s/step - accuracy: 0.8421 - loss: 0.4524 - val_accuracy: 0.7743 - val_loss: 0.6050 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10796s\u001b[0m 58s/step - accuracy: 0.8441 - loss: 0.4421 - val_accuracy: 0.7770 - val_loss: 0.6120 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10668s\u001b[0m 58s/step - accuracy: 0.8412 - loss: 0.4251 - val_accuracy: 0.7947 - val_loss: 0.6126 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11503s\u001b[0m 62s/step - accuracy: 0.8525 - loss: 0.4040 - val_accuracy: 0.7927 - val_loss: 0.5862 - learning_rate: 2.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12181s\u001b[0m 66s/step - accuracy: 0.8487 - loss: 0.4209 - val_accuracy: 0.7961 - val_loss: 0.5785 - learning_rate: 2.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12492s\u001b[0m 68s/step - accuracy: 0.8539 - loss: 0.4089 - val_accuracy: 0.7906 - val_loss: 0.5932 - learning_rate: 2.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12490s\u001b[0m 67s/step - accuracy: 0.8567 - loss: 0.4059 - val_accuracy: 0.7933 - val_loss: 0.5832 - learning_rate: 2.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12258s\u001b[0m 66s/step - accuracy: 0.8582 - loss: 0.3966 - val_accuracy: 0.7872 - val_loss: 0.5975 - learning_rate: 2.0000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12243s\u001b[0m 66s/step - accuracy: 0.8530 - loss: 0.4151 - val_accuracy: 0.7961 - val_loss: 0.5824 - learning_rate: 1.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12130s\u001b[0m 66s/step - accuracy: 0.8624 - loss: 0.4041 - val_accuracy: 0.7879 - val_loss: 0.6050 - learning_rate: 1.0000e-06\n",
      "Model training and fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "base_model = EfficientNetB0(input_shape=(INPUT_SIZE, INPUT_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "output_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    output_layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_checkpoint.keras', save_best_only=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuning the model...\")\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "model.save('The_model.keras')\n",
    "print(\"Model training and fine-tuning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5889 images belonging to 5 classes.\n",
      "Found 1471 images belonging to 5 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
      "Starting training...\n",
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1903s\u001b[0m 10s/step - accuracy: 0.2967 - loss: 1.5891 - val_accuracy: 0.5561 - val_loss: 1.1354 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1782s\u001b[0m 10s/step - accuracy: 0.6137 - loss: 1.0671 - val_accuracy: 0.6594 - val_loss: 0.9294 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2043s\u001b[0m 11s/step - accuracy: 0.6981 - loss: 0.8885 - val_accuracy: 0.7247 - val_loss: 0.8056 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2389s\u001b[0m 13s/step - accuracy: 0.7318 - loss: 0.8083 - val_accuracy: 0.7471 - val_loss: 0.7630 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2505s\u001b[0m 14s/step - accuracy: 0.7371 - loss: 0.7672 - val_accuracy: 0.7478 - val_loss: 0.7347 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2550s\u001b[0m 14s/step - accuracy: 0.7588 - loss: 0.7111 - val_accuracy: 0.7573 - val_loss: 0.7106 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1869s\u001b[0m 10s/step - accuracy: 0.7837 - loss: 0.6571 - val_accuracy: 0.7784 - val_loss: 0.6723 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1898s\u001b[0m 10s/step - accuracy: 0.7872 - loss: 0.6630 - val_accuracy: 0.7621 - val_loss: 0.6725 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1961s\u001b[0m 11s/step - accuracy: 0.7988 - loss: 0.6041 - val_accuracy: 0.7927 - val_loss: 0.6353 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1989s\u001b[0m 11s/step - accuracy: 0.8052 - loss: 0.6106 - val_accuracy: 0.7893 - val_loss: 0.6119 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1929s\u001b[0m 10s/step - accuracy: 0.7979 - loss: 0.5913 - val_accuracy: 0.7893 - val_loss: 0.6274 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1822s\u001b[0m 10s/step - accuracy: 0.8137 - loss: 0.5792 - val_accuracy: 0.8015 - val_loss: 0.5814 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2143s\u001b[0m 12s/step - accuracy: 0.8028 - loss: 0.5731 - val_accuracy: 0.8029 - val_loss: 0.5861 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2090s\u001b[0m 11s/step - accuracy: 0.8101 - loss: 0.5614 - val_accuracy: 0.8090 - val_loss: 0.5767 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1990s\u001b[0m 11s/step - accuracy: 0.8127 - loss: 0.5595 - val_accuracy: 0.8178 - val_loss: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2003s\u001b[0m 11s/step - accuracy: 0.8281 - loss: 0.5299 - val_accuracy: 0.8280 - val_loss: 0.5398 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1986s\u001b[0m 11s/step - accuracy: 0.8269 - loss: 0.5182 - val_accuracy: 0.8199 - val_loss: 0.5495 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 11s/step - accuracy: 0.8229 - loss: 0.5260 - val_accuracy: 0.8246 - val_loss: 0.5463 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2065s\u001b[0m 11s/step - accuracy: 0.8286 - loss: 0.5095 - val_accuracy: 0.8131 - val_loss: 0.5497 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2093s\u001b[0m 11s/step - accuracy: 0.8334 - loss: 0.5082 - val_accuracy: 0.8056 - val_loss: 0.5360 - learning_rate: 2.0000e-05\n",
      "Fine-tuning the model...\n",
      "Epoch 1/20\n",
      "\u001b[1m 52/185\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:58:49\u001b[0m 405s/step - accuracy: 0.6423 - loss: 1.0717"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "\n",
    "# Set mixed precision policy for faster training\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# ImageDataGenerator setup with preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load ResNet50 model with pretrained weights\n",
    "base_model = ResNet50(input_shape=(INPUT_SIZE, INPUT_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "output_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    output_layer\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks for efficient training\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_checkpoint_resnet.keras', save_best_only=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # Adjust layers for fine-tuning\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuning the model...\")\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('The_model_resnet.keras')\n",
    "print(\"Model training and fine-tuning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5889 images belonging to 5 classes.\n",
      "Found 1471 images belonging to 5 classes.\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.3895 - loss: 1.5056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2255s\u001b[0m 12s/step - accuracy: 0.3901 - loss: 1.5046 - val_accuracy: 0.5942 - val_loss: 1.0887 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1888s\u001b[0m 10s/step - accuracy: 0.6555 - loss: 1.0087 - val_accuracy: 0.6954 - val_loss: 0.8905 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2012s\u001b[0m 11s/step - accuracy: 0.7135 - loss: 0.8688 - val_accuracy: 0.7186 - val_loss: 0.8065 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1853s\u001b[0m 10s/step - accuracy: 0.7424 - loss: 0.7882 - val_accuracy: 0.7335 - val_loss: 0.7493 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 10s/step - accuracy: 0.7565 - loss: 0.7184 - val_accuracy: 0.7702 - val_loss: 0.7103 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1942s\u001b[0m 10s/step - accuracy: 0.7665 - loss: 0.7093 - val_accuracy: 0.7927 - val_loss: 0.6582 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1519s\u001b[0m 8s/step - accuracy: 0.7814 - loss: 0.6548 - val_accuracy: 0.7865 - val_loss: 0.6526 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1519s\u001b[0m 8s/step - accuracy: 0.7867 - loss: 0.6452 - val_accuracy: 0.7961 - val_loss: 0.6415 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1510s\u001b[0m 8s/step - accuracy: 0.7898 - loss: 0.6420 - val_accuracy: 0.7811 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1536s\u001b[0m 8s/step - accuracy: 0.7945 - loss: 0.6069 - val_accuracy: 0.8131 - val_loss: 0.5900 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1583s\u001b[0m 9s/step - accuracy: 0.8221 - loss: 0.5695 - val_accuracy: 0.8097 - val_loss: 0.5855 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2015s\u001b[0m 11s/step - accuracy: 0.8121 - loss: 0.5883 - val_accuracy: 0.7879 - val_loss: 0.6044 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1865s\u001b[0m 10s/step - accuracy: 0.8037 - loss: 0.5730 - val_accuracy: 0.8131 - val_loss: 0.5703 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2570s\u001b[0m 14s/step - accuracy: 0.8217 - loss: 0.5408 - val_accuracy: 0.8056 - val_loss: 0.5755 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1512s\u001b[0m 8s/step - accuracy: 0.8206 - loss: 0.5540 - val_accuracy: 0.8083 - val_loss: 0.5581 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1744s\u001b[0m 9s/step - accuracy: 0.8236 - loss: 0.5406 - val_accuracy: 0.8328 - val_loss: 0.5383 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1692s\u001b[0m 9s/step - accuracy: 0.8235 - loss: 0.5342 - val_accuracy: 0.8158 - val_loss: 0.5372 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15799s\u001b[0m 86s/step - accuracy: 0.8312 - loss: 0.5129 - val_accuracy: 0.8232 - val_loss: 0.5273 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1814s\u001b[0m 10s/step - accuracy: 0.8495 - loss: 0.4941 - val_accuracy: 0.8266 - val_loss: 0.5452 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1664s\u001b[0m 9s/step - accuracy: 0.8479 - loss: 0.4829 - val_accuracy: 0.8260 - val_loss: 0.5164 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fine_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     70\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     71\u001b[0m     train_generator,\n\u001b[0;32m     72\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     73\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     74\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[reduce_lr, early_stop, checkpoint]\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Optional fine-tuning: If needed, fine-tune a small portion of the model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fine_tune:\n\u001b[0;32m     79\u001b[0m     base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m150\u001b[39m]:  \u001b[38;5;66;03m# Adjust layers for limited fine-tuning\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fine_tune' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "base_model = ResNet50(input_shape=(INPUT_SIZE, INPUT_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "output_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    output_layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_checkpoint_resnet.keras', save_best_only=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "if fine_tune:\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:150]:  \n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(\"Fine-tuning the model...\")\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        epochs=5,  \n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[reduce_lr, early_stop, checkpoint]\n",
    "    )\n",
    "\n",
    "model.save('The_model_resnet.keras')\n",
    "print(\"Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5889 images belonging to 5 classes.\n",
      "Found 1471 images belonging to 5 classes.\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.3651 - loss: 1.4906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1715s\u001b[0m 9s/step - accuracy: 0.3658 - loss: 1.4896 - val_accuracy: 0.5840 - val_loss: 1.1446 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1540s\u001b[0m 8s/step - accuracy: 0.6503 - loss: 1.0177 - val_accuracy: 0.6635 - val_loss: 0.9299 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1497s\u001b[0m 8s/step - accuracy: 0.7090 - loss: 0.8751 - val_accuracy: 0.7145 - val_loss: 0.8208 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1480s\u001b[0m 8s/step - accuracy: 0.7390 - loss: 0.7746 - val_accuracy: 0.7356 - val_loss: 0.7596 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1487s\u001b[0m 8s/step - accuracy: 0.7579 - loss: 0.7206 - val_accuracy: 0.7573 - val_loss: 0.7312 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1548s\u001b[0m 8s/step - accuracy: 0.7668 - loss: 0.6843 - val_accuracy: 0.7648 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1608s\u001b[0m 9s/step - accuracy: 0.7886 - loss: 0.6564 - val_accuracy: 0.7634 - val_loss: 0.6701 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1626s\u001b[0m 9s/step - accuracy: 0.7919 - loss: 0.6313 - val_accuracy: 0.7675 - val_loss: 0.6617 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1589s\u001b[0m 9s/step - accuracy: 0.8026 - loss: 0.6020 - val_accuracy: 0.7804 - val_loss: 0.6377 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1596s\u001b[0m 9s/step - accuracy: 0.8050 - loss: 0.6072 - val_accuracy: 0.7859 - val_loss: 0.6159 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1616s\u001b[0m 9s/step - accuracy: 0.8050 - loss: 0.5858 - val_accuracy: 0.7995 - val_loss: 0.6046 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1900s\u001b[0m 10s/step - accuracy: 0.7998 - loss: 0.5864 - val_accuracy: 0.7967 - val_loss: 0.6038 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1774s\u001b[0m 10s/step - accuracy: 0.8120 - loss: 0.5653 - val_accuracy: 0.7967 - val_loss: 0.5811 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1657s\u001b[0m 9s/step - accuracy: 0.8217 - loss: 0.5401 - val_accuracy: 0.8185 - val_loss: 0.5661 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1653s\u001b[0m 9s/step - accuracy: 0.8164 - loss: 0.5435 - val_accuracy: 0.8144 - val_loss: 0.5668 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1578s\u001b[0m 9s/step - accuracy: 0.8293 - loss: 0.5227 - val_accuracy: 0.8022 - val_loss: 0.5720 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1555s\u001b[0m 8s/step - accuracy: 0.8238 - loss: 0.5230 - val_accuracy: 0.8097 - val_loss: 0.5478 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1582s\u001b[0m 9s/step - accuracy: 0.8346 - loss: 0.5158 - val_accuracy: 0.8042 - val_loss: 0.5533 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1643s\u001b[0m 9s/step - accuracy: 0.8342 - loss: 0.4986 - val_accuracy: 0.7988 - val_loss: 0.5683 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1682s\u001b[0m 9s/step - accuracy: 0.8309 - loss: 0.4987 - val_accuracy: 0.8260 - val_loss: 0.5299 - learning_rate: 1.0000e-04\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)\n",
    "\n",
    "fine_tune = False  \n",
    "\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "base_model = ResNet50(input_shape=(INPUT_SIZE, INPUT_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "output_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    output_layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_checkpoint_resnet.keras', save_best_only=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "if fine_tune:\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:150]:  \n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(\"Fine-tuning the model...\")\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        epochs=5,  \n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[reduce_lr, early_stop, checkpoint]\n",
    "    )\n",
    "\n",
    "model.save('The_model_resnet.keras')\n",
    "print(\"Model training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
